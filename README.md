# これは何？
公開されているRDFファイルなどのグラフデータを読み込み、Apache Jena FusekiでSPARQLエンドポイント (Webアプリケーション) を作るソースコードである

# 使い方
## 前提条件
- Gitがインストールされていること
- Docker (Docker Engine) がインストールされていること
- Docker Composeがインストールされていること

## このコードのclone
まずこのコードを `git clone` で任意の場所に配置する

## 環境変数の設定
次のコマンドにより `.env` を作る

```sh
cp .env.sample .env
```

生成された `.env` を開き、環境変数を記述する。

`docker compose config` で設定内容が正常にプロンプトに返ってくれば、設定成功である。

## Dockerイメージをbuildする
次のコマンドでイメージをビルドしておく。

```sh
docker compose build
```

## データの配置とロード
### データの配置
- 読み込みたいRDFファイルなどグラフデータを `staging` ディレクトリに置く
- ファイルは複数であっても構わない
- なお受け付けられるファイルの形式は次の通り
    - `*.rdf`
    - `*.rdf.gz`
    - `*.ttl`
    - `*.ttl.gz`
    - `*.owl`
    - `*.owl.gz`
    - `*.nt`
    - `*.nt.gz`
    - `*.nquads`
    - `*.nquads.gz`

### データのロード
#### 注意事項
まずこの手順を始める前に、次の点を認識し留意すること。

1. この工程は所要時間が長い (日化辞RDFファイルを読み込ませる場合、コマンド実行後45分程度時間を要する)
2. 多量のメモリを要する (日化辞RDFファイルを読み込ませる場合、コマンド実行後約30GBのメモリが消費される。また少ないメモリでこの工程を実行した場合、メモリ不足エラーによりコマンドが途中で強制的にkillされてしまう)
3. 中程度量のディスクを使用する (日化辞RDFファイルを読み込ませた場合、20GB程度のディスク使用量増加がある)
4. `fuseki` コンテナは停止した状態でコマンドを始めること (そうでない場合、エラーが出て止まる)

#### 手順
次のコマンドにより、データをDockerコンテナに読み込ませる。

```sh
docker compose run --rm fuseki ./load.sh <任意のデータセット名称> <stagingフォルダ内の読み込むファイル>
```

例えば `staging` フォルダに配置したすべての `.ttl.gz` 拡張子ファイルを読み込み、結果として `nikkaji` というデータセットをFuseki内に設けるなら、具体的には次のコマンドになる。

```sh
docker compose run --rm fuseki ./load.sh nikkaji *.ttl.gz
```

コマンド実行後、`complete` を知らせる表示 (`Finish quads load`) がプロンプトに現れれば成功である (その表示が現れれば、`Ctrl + C` でプロンプトを戻しても構わない)。

### Fusekiの起動と、ロードしたデータセットの設定
まず次のコマンドでFusekiのサービスを立ち上げる

```sh
docker compose up -d
```

立ち上げたFusekiサービスにウェブブラウザ画面から入る。(立ち上げたFusekiサービスがあるサーバ・ポートへのアクセス許可設定 (ファイアーウォール設定など) は、あらかじめしておくこと。)

ユーザー名とパスワードが要求されるため、以下の要領でログインする

- ユーザー名: `admin`
- パスワード: `.env` ファイルに記述したパスワード

次に、以下の要領でデータセットの設定をする

- 画面上部のメニューバーから `manage dataset` メニューをクリックして画面に入る
- `Add new dataset` をクリックする
- `dataset name` に、`load.sh` に与えた "任意のデータセット名称" と正確に同じ文字列を入力する (例えば先の手順で `nikkaji` というデータセット名称を与えたならば、それをここで入力する)
- `Dataset type` は `Persistent` を選択し、 `create dataset` ボタンを押す
- 画面上部のメニューバーから `dataset` をクリックした後、画面上部の `Dataset:` ドロップダウンメニューで、先ほど入力したデータセットが選択されていることを確認する
- 画面にはサンプルのSPARQLクエリが自動で入力されているので、画面右側の再生ボタンをクリックしてクエリ結果が表示されれば、一連のSPARQLエンドポイントの作成は成功である

# 重要参考情報
https://hub.docker.com/r/stain/jena-fuseki#Data_persistence
